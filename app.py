from chainlit import AskUserMessage, Message, on_chat_start
from langchain.llms import OpenAI
from langchain import LLMChain
from langchain.prompts.prompt import PromptTemplate
from langchain.memory import ConversationBufferMemory
import os
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
import chainlit as cl
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.prompts import HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage
import openai
import json



os.environ["OPENAI_API_KEY"] = "" #Add your open api key here
openai.api_key = ""#Add your open api key here
base_llm = OpenAI()
chat_model = ChatOpenAI()

template_main = """
You are an AI chatbot.
Your mission is to extract the information from the user through a friendly talk without making the user feel that his or her information is being extracted.
Follow the below rules :
- Contine the conversation from the last chat.
- Don't ask direct questions like "What is your name?", "What is your birth date?",
- If the user is hesitant then initiate small talk and later circle back to the question regarding their personal information.
- Details to extract: Name, email, phone no, Address, Date of birth, Education.
- Make sure the Chat flow is consistent or natural and minimum hallucinations (No question repetitions, out of context question) shouldnâ€™t happen.
- You will as questions to the user.
- If the user is not willing to provide the information about his or her name, age , date of birth , education, address, phone number,etc please have a friendly talk with the user and indirectly ask aabout the details and don't hallucinate in doing so.
- Please don't repeat the questions.

{query}
"""

template_randomised_questions = """
You are an AI chatbot.
Your mission is to extract the information from the user through a friendly talk without making the user feel that his or her information is being extracted.
- Details to extract: Name, email, phone no, Address, Date of birth, Education.
- Don't ask direct questions like "What is your name?", "What is your birth date?",
- Also dont add sentances like - 'Let's start the chat' and other to make the user feel its talking to a chatbot
So,help me generate a random question to start the conversation with it the user. It can a small talk or a friendly talk, etc.
Once i add "Let's start the chat", Your response should be a question only.
"""

ner_gpt_function = [
        {
            "name": "find_ner",
            "description": "Extracts name, age , phone number, address, and date of birth from the input chathistory given.",
            "parameters": {
                "type": "object",
                "properties": {
                    "entities": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "entity":{"type": "string", 
                                          "description": "A Named entity extracted from text."},
                                "catrgory":{"type": "string", 
                                            "description": "Category of the named entity."}
                            }                            
                          }
                        }
                    }
                },
                "required": ["entities"]
            }
        ]
template_main_prompt = PromptTemplate(
    input_variables=["query"],
    template=template_main
)
template_randomised_questions_prompt = PromptTemplate(
    input_variables=[],
    template=template_randomised_questions
)

global_variable=0


new_memory_main = ConversationBufferMemory(memory_key="chat_history")

new_memory_randomised = ConversationBufferMemory(memory_key="chat_history")

new_memory_extraction = ConversationBufferMemory(memory_key="chat_history")

# Start Here

llm_chatbot_randomised = LLMChain(llm=OpenAI(
    temperature=0.8), prompt=template_randomised_questions_prompt, verbose=True, memory=new_memory_randomised)


def extract_information():
    response = openai.ChatCompletion.create(
        model='gpt-3.5-turbo',
        messages=[{"role": "user", "content": new_memory_main.load_memory_variables({})['chat_history']}],
            functions=ner_gpt_function,
            function_call={"name": "find_ner"},)
    
    save_file = open("savedata.json", "w")  
    json.dump(response['choices'][0]['message']['function_call']['arguments'], save_file, indent = 6)  
    save_file.close()  
    print(response['choices'][0]['message']['function_call']['arguments'])


def generate_randomised_response(human_input):
    response = llm_chatbot_randomised.predict(human_input='',chat_history='')
    return response


@cl.on_chat_start
async def main():
        res = await AskUserMessage(content=generate_randomised_response("Let's start the chat"), timeout=10).send()
        conv_main_chain = LLMChain(llm=OpenAI(
            temperature=0.8), prompt=template_main_prompt, verbose=True, memory=new_memory_main)
        cl.user_session.set('llm_chain',conv_main_chain)

@cl.on_message
async def main(message: str):
    #   chain = cl.user_session.get("llm_chain")  # type: LLMChain

    # res = await chain.arun(
    #     question=message.content, callbacks=[cl.LangchainCallbackHandler()]
    # )

    # await cl.Message(content=res).send()
     llm_chain = cl.user_session.get('llm_chain')
     res = await llm_chain.acall(message.content,callbacks=[cl.AsyncLangchainCallbackHandler()])
     if res:
        await cl.Message(content=res['text']).send()
        global global_variable 
        print(global_variable)
        global_variable +=1
        if global_variable%5==0:
             extract_information()

    

